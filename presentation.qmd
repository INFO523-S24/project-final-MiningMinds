---
title: "Fraud Detection Using Ensemble Learning"
subtitle: "Team : Mining Minds -INFO 523- Spring 2023 - Project Final"
author: "Omid Zandi,Nandhini Anne, Sai Navya Reddy Busireddy, Gowtham Gopalkrishnan, Roxana Akbarsharifi, Deema Albluwi"
title-slide-attributes:
  data-background-image: images/title1.png
  data-background-size: stretch
  data-background-opacity: "0.2"
  data-slide-number: none
format:
  revealjs:
    theme:  ['data/customtheming.scss']
    background-transition: fade
    transition: slide
    auto-animate-duration: 1.5
    scrollable: true
    logo: images/credit_card_fraud.jpeg
    footer: "[ðŸ’µ MiningMinds](https://info523-s24.github.io/project-final-MiningMinds/)"
  
editor: visual
jupyter: python3
execute:
  echo: false
  warning: false
  message: false
editor_options:
    chunk_output_type: console
---

```{python}
#| label: load-packages
#| include: false

# Load packages here
import pandas as pd
import seaborn as sns
import joblib


```

```{python}
#| label: setup
#| include: false
#| 
# Set up plot theme and figure resolution
sns.set_theme(style="whitegrid")
sns.set_context("notebook", font_scale=1.1)

import matplotlib.pyplot as plt
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['figure.figsize'] = (6, 6 * 0.618)
```


## Introduction {style="font-size: 0.7em;"}
::: incremental

-   The primary goal of our project is to enhance machine learning models accuracy in detecting fraudulent credit card transactions using an ensemble learning technique known as stacked generalization.

-   The motivation behind our project is to improve the detection of fraudulent transactions, which remains a significant challenge in financial security.

-   By integrating multiple predictive models, the project aims to create a robust system that can more accurately identify fraudulent transactions, thus contributing to safer financial environments.

-   Despite challenges like data imbalance and feature anonymization, we anticipate that stacked generalization will enhance fraud detection accuracy, demonstrating the effectiveness of ensemble methods in complex scenarios.

:::

## Dataset description {style="font-size: 0.7em;"}
::: incremental
-   The dataset comprises over 550,000 credit card transactions from European cardholders, collected in 2023.

-   It includes 31 features with transaction details such as amount and time, anonymized to ensure privacy and ethical compliance.

-   The anonymization of features presents challenges in interpreting the data, while the class imbalance poses difficulties in model training and accuracy.

:::



## Preview of the Dataset: First Few Transactions {style="font-size: 0.7em;"}


<br>

```{python}
#| label: Importing Libraries

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.patches as mpatches
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from mlxtend.classifier import StackingClassifier
import joblib

```
```{python}
#| label: Reading the dataset

df = pd.read_csv('./data/creditcard.csv')
df.head()

```


```{python}
#| label: Scaling Time and Amount
scaler = StandardScaler()

df['scaled_amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1,1))
df['scaled_time'] = scaler.fit_transform(df['Time'].values.reshape(-1,1))

df.drop(['Time','Amount'], axis=1, inplace=True)

# Move Class column to the end
cols = [col for col in df if col != 'Class'] + ['Class']
df = df[cols]
```



## Research Questions {style="font-size: 0.7em;"}
::: incremental

-   What is the comparative performance of anomaly detection algorithms, including Random Forest, XGBoost, KNN, for fraud detection in this specific dataset?

-   How does the stacked generalization technique, implemented with the mlxtend library, improve fraud detection performance by leveraging the synergy between base classifiers?

:::

## Question1: Analysis Plan {style="font-size: 0.7em;"}
::: incremental

-  <b>Model Training and Sampling Techniques:</b> Address dataset imbalance by oversampling the minority class and undersampling the majority. Split the data into training and testing sets, and train anomaly detection models including Random Forest, XGBoost, and KNN.

-  <b>Model Optimization:</b> Hypertune the models to optimize performance, ensuring the best possible settings for each algorithm.

-  <b>Performance Evaluation and Analysis:</b> Evaluate each model on the testing set using metrics like precision, recall, F1-score, and ROC area. Analyze performance differences to understand the impact of model complexity, feature importance, and dataset characteristics.

:::




## Question2: Analysis Plan {style="font-size: 0.7em;"}
::: incremental

-  <b>Stacked Generalization Setup:</b> Utilize the mlxtend library to implement stacked generalization. Train base models as specified, and split their output into training and testing sets for the meta-classifier.

-  <b>Meta-classifier Training:</b> Combine predictions from base classifiers using the stacking method, and train a meta-classifier on these combined predictions to enhance prediction accuracy.

-  <b>Evaluation and Analysis:</b> Assess the performance of the stacked model, compare it to the base models, and analyze the performance gains, focusing on factors like model diversity, ensemble principles, and dataset specifics.

:::


## Random Undersampling {style="font-size: 0.7em;"}
::: incremental

```{python}
#| label: Original dataset
# Creating a DataFrame
class_counts_df = pd.DataFrame({
    'Class': ['non-fradulent', 'fradulent'],
    'Values': [df['Class'].value_counts()[0], df['Class'].value_counts()[1]]})

# Creating the barplot
plt.figure(figsize=(8, 4))
bar_plot = sns.barplot(x='Class', y='Values', data=class_counts_df, palette=['skyblue', 'red'])

# Adding labels and title
plt.xlabel('Categories')
plt.ylabel('Values')
plt.title('Comparison of the Number of Classes')

# Find the maximum value to adjust y limits accordingly
max_value = class_counts_df['Values'].max()
plt.ylim(0, max_value + 0.1 * max_value)  # Increase upper limit by 10% of the max value

# Annotate the number of samples in each class
for p in bar_plot.patches:  # iterate through the list of bars
    bar_plot.annotate(format(p.get_height(), '.0f'), 
                       (p.get_x() + p.get_width() / 2., p.get_height()), 
                       ha = 'center', va = 'center', 
                       size=10, xytext = (0, 8), 
                       textcoords = 'offset points')

plt.show()

```


```{python}
#| label: Undersampled dataset

# Shuffling the dataset
df = df.sample(frac=1)

# amount of fraud classes 492 rows.
fraud_df = df.loc[df['Class'] == 1]
non_fraud_df = df.loc[df['Class'] == 0][:492]

balanced_df = pd.concat([fraud_df, non_fraud_df])

# Shuffle dataframe rows
new_df = balanced_df.sample(frac=1, random_state=42)

new_df.head()


# Creating a DataFrame
class_counts_df = pd.DataFrame({
    'Class': ['non-fradulent', 'fradulent'],
    'Values': [balanced_df['Class'].value_counts()[0], balanced_df['Class'].value_counts()[1]]})

# Creating the barplot
plt.figure(figsize=(8, 4))
bar_plot = sns.barplot(x='Class', y='Values', data=class_counts_df, palette=['skyblue', 'red'])

# Adding labels and title
plt.xlabel('Categories')
plt.ylabel('Values')
plt.title('Comparison of the Number of Classes')

# Find the maximum value to adjust y limits accordingly
max_value = class_counts_df['Values'].max()
plt.ylim(0, max_value + 0.1 * max_value)  # Increase upper limit by 10% of the max value

# Annotate the number of samples in each class
for p in bar_plot.patches:  # iterate through the list of bars
    bar_plot.annotate(format(p.get_height(), '.0f'), 
                       (p.get_x() + p.get_width() / 2., p.get_height()), 
                       ha = 'center', va = 'center', 
                       size=10, xytext = (0, 8), 
                       textcoords = 'offset points')

plt.show()

```



:::

## EDA  {style="font-size: 0.7em;"}
::: panel-tabset
### Kernel Density Plots
```{python}
#| label: Kernel Density Plots
# Pre-compute class-specific datasets
non_fraud_df = new_df[new_df['Class'] == 0].drop('Class', axis=1)
fraud_df = new_df[new_df['Class'] == 1].drop('Class', axis=1)

# Setup the figure and axes
fig, axes = plt.subplots(5, 6, figsize=(16, 10))  # Adjust the grid dimensions based on the number of columns
axes = axes.flatten()  # Flatten the array for easy iteration

for i, col in enumerate(new_df.columns[:-1]):  # Assuming the last column is 'Class' and it's dropped
    sns.histplot(data=non_fraud_df[col], bins=50, kde=True, color='blue', ax=axes[i], label='Non-Fraud' if i == 0 else "")
    sns.histplot(data=fraud_df[col], bins=50, kde=True, color='red', ax=axes[i], label='Fraud' if i == 0 else "")
    axes[i].set_title(f'Distribution of {col}', fontsize=10)
    axes[i].set_xlabel('')  # Clear x-labels to reduce clutter
    axes[i].set_ylabel('')  # Optionally clear y-labels for the same reason
    if i == 0:  # Add legend only to the first subplot
        axes[i].legend()

# Adjust layout to prevent label/title overlap
plt.tight_layout()
plt.show()

```


### PCA
```{python}
#| label: PCA

# New_df is from the random undersample data (fewer instances)
X = new_df.drop('Class', axis=1)
y = new_df['Class']

# PCA Implementation
X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(X.values)

# PCA scatter plot
f, ax = plt.subplots(1, 1, figsize=(8, 6))  # Adjust the figsize as needed for a single plot

blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')
red_patch = mpatches.Patch(color='#AF0000', label='Fraud')

ax.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)
ax.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)
ax.set_title('PCA', fontsize=14)

ax.grid(True)

ax.legend(handles=[blue_patch, red_patch])
```

:::


## RandomForest Classifier  {style="font-size: 0.7em;"}
::: panel-tabset
### Plot
```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import matplotlib.patches as mpatches
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from mlxtend.classifier import StackingClassifier 
```

```{python}
df = pd.read_csv('./data/creditcard.csv')
# Creating a DataFrame
class_counts_df = pd.DataFrame({
    'Class': ['non-fradulent', 'fradulent'],
    'Values': [df['Class'].value_counts()[0], df['Class'].value_counts()[1]]})
# Shuffling the dataset
df = df.sample(frac=1)

# amount of fraud classes 492 rows.
fraud_df = df.loc[df['Class'] == 1]
non_fraud_df = df.loc[df['Class'] == 0][:492]

balanced_df = pd.concat([fraud_df, non_fraud_df])

# Shuffle dataframe rows
new_df = balanced_df.sample(frac=1, random_state=42)
# New_df is from the random undersample data (fewer instances)
X = new_df.drop('Class', axis=1)
y = new_df['Class']

# PCA Implementation
X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(X.values)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

```
```{python}
# # Parameters for Random Forest
# rf_params = {
#     'n_estimators': [10, 50, 100, 200],
#     'max_depth': [None, 10, 20, 30],
#     'min_samples_split': [2, 5, 10],
#     'min_samples_leaf': [1, 2, 4]
# }

# # Parameters for K-Nearest Neighbors
# knears_params = {
#     'n_neighbors': list(range(2, 5, 1)),
#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']
# }

# # Parameters for XGBoost
# xgb_params = {
#     'n_estimators': [100, 200],
#     'max_depth': [3, 5, 7, 9],
#     'learning_rate': [0.01, 0.1, 0.2],
#     'subsample': [0.7, 0.8, 0.9]
# }

# # Setup GridSearchCV for Random Forest
# grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='accuracy', n_jobs=-1)
# grid_rf.fit(X_train, y_train)
# rf_best = grid_rf.best_estimator_

# # Setup GridSearchCV for K-Nearest Neighbors
# grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params, cv=5, scoring='accuracy', n_jobs=-1)
# grid_knears.fit(X_train, y_train)
# knears_best = grid_knears.best_estimator_

# # Setup GridSearchCV for XGBoost
# grid_xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42), xgb_params, cv=5, scoring='accuracy', n_jobs=-1)
# grid_xgb.fit(X_train, y_train)
# xgb_best = grid_xgb.best_estimator_
```

```{python}

rf_best = joblib.load('./_extra/rf_best.joblib')
knears_best = joblib.load('./_extra/knears_best.joblib')
xgb_best = joblib.load('./_extra/xgb_best.joblib')

```


```{python}
y_pred_rf = rf_best.predict(X_test)

# Calculating performance metrics for Random Forest
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)
cm_rf = confusion_matrix(y_test, y_pred_rf)
# Plotting the confusion matrix for Random Forest using Matplotlib
fig, ax = plt.subplots(figsize=(7,5))
ax.matshow(cm_rf, cmap='viridis', alpha=0.3)
for i in range(cm_rf.shape[0]):
    for j in range(cm_rf.shape[1]):
        ax.text(x=j, y=i, s=cm_rf[i, j], va='center', ha='center', size='large')

# Correcting the axis inversion
ax.invert_xaxis()
ax.invert_yaxis()

# Setting tick positions explicitly
ax.set_xticks([0, 1])  # Assuming there are two classes
ax.set_yticks([0, 1])

# Adding corrected labels
labels = ['Non-Fraudulent', 'Fraudulent']  # Correcting typo in 'Fraudulent'
ax.set_xticklabels(labels, fontsize=10)
ax.set_yticklabels(labels, fontsize=10)

# Adding axis labels and title for Random Forest
plt.xlabel('Predictions', fontsize=12)
plt.ylabel('Observations', fontsize=12)
plt.title('RandomForest', fontsize=12)
plt.tight_layout()
plt.show()

```

### Metrics
```{python}
print("Random Forest has", round(accuracy_rf, 2), "accuracy")
print("Random Forest has", round(precision_rf, 2), "precision")
print("Random Forest has", round(recall_rf, 2), "recall")
print("Random Forest has", round(f1_rf, 2), "f1 score")
```

:::

## KNN Classifier {style="font-size: 0.7em;"}
::: panel-tabset
### Plot
```{python}
y_pred_knn = knears_best.predict(X_test)

# Calculating performance metrics for KNN
accuracy_knn = accuracy_score(y_test, y_pred_knn)
precision_knn = precision_score(y_test, y_pred_knn)
recall_knn = recall_score(y_test, y_pred_knn)
f1_knn = f1_score(y_test, y_pred_knn)
cm_knn = confusion_matrix(y_test, y_pred_knn)

# Plotting the confusion matrix for KNN using Matplotlib
fig, ax = plt.subplots(figsize=(7,5))
ax.matshow(cm_knn, cmap='viridis', alpha=0.3)
for i in range(cm_knn.shape[0]):
    for j in range(cm_knn.shape[1]):
        ax.text(x=j, y=i, s=cm_knn[i, j], va='center', ha='center', size='large')

# Correcting the axis inversion
ax.invert_xaxis()
ax.invert_yaxis()

# Setting tick positions explicitly
ax.set_xticks([0, 1])  # Assuming there are two classes
ax.set_yticks([0, 1])

# Adding corrected labels
labels = ['Non-Fraudulent', 'Fraudulent']  # Correcting typo in 'Fraudulent'
ax.set_xticklabels(labels, fontsize=10)
ax.set_yticklabels(labels, fontsize=10)

# Adding axis labels and title for KNN
plt.xlabel('Predictions', fontsize=12)
plt.ylabel('Observations', fontsize=12)
plt.title('KNearest', fontsize=12)
plt.show()
```
### Metrics
```{python}

print("KNN has", round(accuracy_knn, 2), "accuracy")
print("KNN has", round(precision_knn, 2), "precision")
print("KNN has", round(recall_knn, 2), "recall")
print("KNN has", round(f1_knn, 2), "f1 score")
```

:::

## XGBoost Classifier {style="font-size: 0.7em;"}
::: panel-tabset
### Plot
```{python}
y_pred_xgb = xgb_best.predict(X_test)

# Calculating performance metrics for XGBoost
accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
precision_xgb = precision_score(y_test, y_pred_xgb)
recall_xgb = recall_score(y_test, y_pred_xgb)
f1_xgb = f1_score(y_test, y_pred_xgb)
cm_xgb = confusion_matrix(y_test, y_pred_xgb)

# Plotting the confusion matrix for XGBoost using Matplotlib
fig, ax = plt.subplots(figsize=(7,5))
ax.matshow(cm_xgb, cmap='viridis', alpha=0.3)
for i in range(cm_xgb.shape[0]):
    for j in range(cm_xgb.shape[1]):
        ax.text(x=j, y=i, s=cm_xgb[i, j], va='center', ha='center', size='large')

# Correcting the axis inversion
ax.invert_xaxis()
ax.invert_yaxis()

# Setting tick positions explicitly
ax.set_xticks([0, 1])  # Assuming there are two classes
ax.set_yticks([0, 1])

# Adding corrected labels
labels = ['Non-Fraudulent', 'Fraudulent']  # Correcting typo in 'Fraudulent'
ax.set_xticklabels(labels, fontsize=10)
ax.set_yticklabels(labels, fontsize=10)

# Adding axis labels and title for XGBoost
plt.xlabel('Predictions', fontsize=12)
plt.ylabel('Observations', fontsize=12)
plt.title('XGBoost', fontsize=12)

plt.show()
```
### Metrics
```{python}
print("XGBoost has", round(accuracy_xgb, 2), "accuracy")
print("XGBoost has", round(precision_xgb, 2), "precision")
print("XGBoost has", round(recall_xgb, 2), "recall")
print("XGBoost has", round(f1_xgb, 2), "f1 score")
```

:::

## Stacked Model {style="font-size: 0.7em;"}
::: panel-tabset
### Plot
```{python}
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

# Assuming rf_best, knears_best, and xgb_best are previously defined models
# Correcting the initialization of StackingClassifier
stack_clf = StackingClassifier(
    estimators=[
        ('RandomForest', rf_best),
        ('KNearest', knears_best),
        ('XGBoost', xgb_best)
    ],
    final_estimator=LogisticRegression(random_state=42)
)

# Fitting the model
stack_clf.fit(X_train, y_train)

# Rest of your code for predictions and evaluations
classifiers = {
    "Stacked Model": stack_clf
}

for key, classifier in classifiers.items():
    y_pred = classifier.predict(X_test)

    # Calculating performance metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)

    # Plotting the confusion matrix using Matplotlib
    fig, ax = plt.subplots(figsize=(7,5))
    ax.matshow(cm, cmap='viridis', alpha=0.3)
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(x=j, y=i, s=cm[i, j], va='center', ha='center', size='large')

    # Setting tick positions and labels
    ax.set_xticks([0, 1])  # Assuming two classes
    ax.set_yticks([0, 1])
    labels = ['Non-Fraudulent', 'Fraudulent']
    ax.set_xticklabels(labels, fontsize=10)
    ax.set_yticklabels(labels, fontsize=10)

    # Adding axis labels and title
    plt.xlabel('Predictions', fontsize=12)
    plt.ylabel('Observations', fontsize=12)
    plt.title(key, fontsize=18)

    plt.show()


    
```
### Metrics
```{python}
print("Classifiers: ", key, "has", round(accuracy, 2), "accuracy")
print("Classifiers: ", key, "has", round(precision, 2), "precision")
print("Classifiers: ", key, "has", round(recall, 2), "recall")
print("Classifiers: ", key, "has", round(f1, 2), "f1 score")

```
:::

## ROC curve {style="font-size: 0.7em;"}
::: panel-tabset
### Plot
```{python}
rf_probs_test = rf_best.predict_proba(X_test)[:, 1]
knears_probs_test = knears_best.predict_proba(X_test)[:, 1]
xgb_probs_test = xgb_best.predict_proba(X_test)[:, 1]
stack_probs_test = stack_clf.predict_proba(X_test)[:, 1]

rf_fpr_test, rf_tpr_test, _ = roc_curve(y_test, rf_probs_test)
knears_fpr_test, knears_tpr_test, _ = roc_curve(y_test, knears_probs_test)
xgb_fpr_test, xgb_tpr_test, _ = roc_curve(y_test, xgb_probs_test)
stack_fpr_test, stack_tpr_test, _ = roc_curve(y_test, stack_probs_test)

def plot_roc_curve():
    plt.figure(figsize=(10, 6))
    plt.plot(rf_fpr_test, rf_tpr_test, label='Random Forest (AUC = %0.3f)' % roc_auc_score(y_test, rf_probs_test))
    plt.plot(knears_fpr_test, knears_tpr_test, label='KNN (AUC = %0.3f)' % roc_auc_score(y_test, knears_probs_test))
    plt.plot(xgb_fpr_test, xgb_tpr_test, label='XGBoost (AUC = %0.3f)' % roc_auc_score(y_test, xgb_probs_test))
    plt.plot(stack_fpr_test, stack_tpr_test, label='Stacked Classifier (AUC = %0.3f)' % roc_auc_score(y_test, stack_probs_test))
    plt.plot([0, 1], [0, 1], 'r--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves for Test Data')
    plt.legend(loc="lower right")
    plt.show()

plot_roc_curve()
```
### Analysis
::: incremental
- <b>Excellent Performance:</b> The Random Forest, XGBoost, and Stacked Classifier show excellent performance with AUC values near 1, indicating strong ability to distinguish between classes.
- <b>KNN Underperforms:</b> The KNN model significantly underperforms with a much lower AUC of 0.705, indicating it is less effective at class discrimination in this dataset.
:::
:::

##
![](images/thankyou.jpg){style="width:100%;height:100%;"}