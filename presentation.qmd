---
title: "Fraud Detection Using Ensemble Learning"
subtitle: "Team : Mining Minds -INFO 523- Spring 2023 - Project Final"
author: "Omid Zandi,Nandhini Anne, Sai Navya Reddy Busireddy, Gowtham Gopalkrishnan, Roxana Akbarsharifi, Deema Albluwi"
title-slide-attributes:
  data-background-image: images/title1.png
  data-background-size: stretch
  data-background-opacity: "0.2"
  data-slide-number: none
format:
  revealjs:
    theme:  ['data/customtheming.scss']
    background-transition: fade
    transition: slide
    auto-animate-duration: 1.5
    scrollable: true
    logo: images/credit_card_fraud.jpeg
  
editor: visual
jupyter: python3
execute:
  echo: false
  warning: false
  message: false
editor_options:
    chunk_output_type: console
---

```{python}
#| label: load-packages
#| include: false

# Load packages here
import pandas as pd
import seaborn as sns

```

```{python}
#| label: setup
#| include: false
#| 
# Set up plot theme and figure resolution
sns.set_theme(style="whitegrid")
sns.set_context("notebook", font_scale=1.1)

import matplotlib.pyplot as plt
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['figure.figsize'] = (6, 6 * 0.618)
```

```{python}
#| label: load-data
#| include: false
# Load data in Python
mtcars = sns.load_dataset('mpg').dropna()  # mtcars dataset is similar to the mpg dataset from seaborn
mtcars['speed'] = mtcars['horsepower'] / mtcars['weight']

penguins = sns.load_dataset('penguins').dropna()
```


## Introduction {style="font-size: 0.7em;"}
::: incremental

-   The primary goal of our project is to enhance machine learning models accuracy in detecting fraudulent credit card transactions using an ensemble learning technique known as stacked generalization.

-   The motivation behind our project is to improve the detection of fraudulent transactions, which remains a significant challenge in financial security.

-   By integrating multiple predictive models, the project aims to create a robust system that can more accurately identify fraudulent transactions, thus contributing to safer financial environments.

-   Despite challenges like data imbalance and feature anonymization, we anticipate that stacked generalization will significantly enhance fraud detection accuracy, demonstrating the effectiveness of ensemble methods in complex scenarios.

:::

## Dataset description {style="font-size: 0.7em;"}
::: incremental
-   The dataset comprises over 550,000 credit card transactions from European cardholders, collected in 2023.

-   It includes 31 features with transaction details such as amount and time, anonymized to ensure privacy and ethical compliance.

-   Features include a unique transaction ID and 28 anonymized attributes (V1-V28), representing various transaction details.

-   The anonymization of features presents challenges in interpreting the data, while the class imbalance poses difficulties in model training and accuracy.

:::



## Preview of the Dataset: First Few Transactions {style="font-size: 0.7em;"}


<br>

```{python}
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.patches as mpatches
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, f1_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from mlxtend.classifier import StackingClassifier

df = pd.read_csv('./data/creditcard.csv')
df.head()


```

## Research Questions {style="font-size: 0.7em;"}
::: incremental

-   What is the comparative performance of anomaly detection algorithms, including Random Forest, XGBoost, KNN, for fraud detection in this specific dataset?

-   How does the stacked generalization technique, implemented with the mlxtend library, improve fraud detection performance by leveraging the synergy between base classifiers?

:::

## Question1: Analysis Plan {style="font-size: 0.7em;"}
::: incremental

-  <b>Model Training and Sampling Techniques:</b> Address dataset imbalance by oversampling the minority class and undersampling the majority. Split the data into training and testing sets, and train anomaly detection models including Random Forest, XGBoost, and KNN.

-  <b>Model Optimization:</b> Hypertune the models to optimize performance, ensuring the best possible settings for each algorithm.

-  <b>Performance Evaluation and Analysis:</b> Evaluate each model on the testing set using metrics like precision, recall, F1-score, and ROC area. Analyze performance differences to understand the impact of model complexity, feature importance, and dataset characteristics.

:::

## Plot

```{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_csv('./data/creditcard.csv')
# Creating a DataFrame
class_counts_df = pd.DataFrame({
    'Class': ['non-fradulent', 'fradulent'],
    'Values': [df['Class'].value_counts()[0], df['Class'].value_counts()[1]]})

# Creating the barplot
plt.figure(figsize=(8, 4))
bar_plot = sns.barplot(x='Class', y='Values', data=class_counts_df, palette=['skyblue', 'red'])

# Adding labels and title
plt.xlabel('Categories')
plt.ylabel('Values')
plt.title('Comparison of the Number of Classes')

# Find the maximum value to adjust y limits accordingly
max_value = class_counts_df['Values'].max()
plt.ylim(0, max_value + 0.1 * max_value)  # Increase upper limit by 10% of the max value

# Annotate the number of samples in each class
for p in bar_plot.patches:  # iterate through the list of bars
    bar_plot.annotate(format(p.get_height(), '.0f'), 
                       (p.get_x() + p.get_width() / 2., p.get_height()), 
                       ha = 'center', va = 'center', 
                       size=10, xytext = (0, 8), 
                       textcoords = 'offset points')

plt.show()

```


## Plot 2
```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_csv('./data/creditcard.csv')
# Calculate quartiles and IQR to set appropriate y-axis limits
q1 = np.percentile(df['Amount'], 25)
q3 = np.percentile(df['Amount'], 75)
iqr = q3 - q1

# Define bounds to zoom in closer around the quartiles, reducing the range to focus on main data
lower_bound = q1 - 0.5 * iqr
upper_bound = q3 + 3 * iqr

# Create the boxplots without outliers
fig, ax = plt.subplots(figsize=(8, 6))
df.boxplot(column='Amount', by='Class', ax=ax, showfliers=False)

# Adding titles and labels
plt.title('Transaction Amount by Fraudulence')
plt.suptitle('')  # Suppress the automatic title
plt.ylabel('Transaction Amount')

# Change x-axis labels from '0', '1' to 'Non-Fraudulent', 'Fraudulent'
ax.set_xticklabels(['Non-Fraudulent', 'Fraudulent'])

# Format y-axis to show dollar signs and set y-axis limits to focus around the IQR
ax.set_yticklabels(['${:,.0f}'.format(y) for y in ax.get_yticks()])
plt.ylim(lower_bound, upper_bound)

# Remove vertical grid lines
ax.xaxis.grid(False)  # Disable x-axis grid lines
ax.yaxis.grid(True)   # Keep y-axis grid lines for better readability

# Show plot
plt.tight_layout()
plt.show()
```


## Plot 3
::: inremental
-Let's check if the number of samples in each class are equal.
```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_csv('./data/creditcard.csv')
# amount of fraud classes 492 rows.
fraud_df = df.loc[df['Class'] == 1]
non_fraud_df = df.loc[df['Class'] == 0][:492]

balanced_df = pd.concat([fraud_df, non_fraud_df])

# Shuffle dataframe rows
new_df = balanced_df.sample(frac=1, random_state=42)
# Creating a DataFrame
class_counts_df = pd.DataFrame({
    'Class': ['non-fradulent', 'fradulent'],
    'Values': [balanced_df['Class'].value_counts()[0], balanced_df['Class'].value_counts()[1]]})

# Creating the barplot
plt.figure(figsize=(8, 4))
bar_plot = sns.barplot(x='Class', y='Values', data=class_counts_df, palette=['skyblue', 'red'])

# Adding labels and title
plt.xlabel('Categories')
plt.ylabel('Values')
plt.title('Comparison of the Number of Classes')

# Find the maximum value to adjust y limits accordingly
max_value = class_counts_df['Values'].max()
plt.ylim(0, max_value + 0.1 * max_value)  # Increase upper limit by 10% of the max value

# Annotate the number of samples in each class
for p in bar_plot.patches:  # iterate through the list of bars
    bar_plot.annotate(format(p.get_height(), '.0f'), 
                       (p.get_x() + p.get_width() / 2., p.get_height()), 
                       ha = 'center', va = 'center', 
                       size=10, xytext = (0, 8), 
                       textcoords = 'offset points')

plt.show()
```
:::

## Plot4 PCA scatter plot
::: incremental
```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import matplotlib.patches as mpatches
import seaborn as sns
df = pd.read_csv('./data/creditcard.csv')
# New_df is from the random undersample data (fewer instances)
# amount of fraud classes 492 rows.
fraud_df = df.loc[df['Class'] == 1]
non_fraud_df = df.loc[df['Class'] == 0][:492]

balanced_df = pd.concat([fraud_df, non_fraud_df])

# Shuffle dataframe rows
new_df = balanced_df.sample(frac=1, random_state=42)

new_df.head()
X = new_df.drop('Class', axis=1)
y = new_df['Class']

# PCA Implementation
X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(X.values)

# PCA scatter plot
f, ax = plt.subplots(1, 1, figsize=(8, 6))  # Adjust the figsize as needed for a single plot

blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')
red_patch = mpatches.Patch(color='#AF0000', label='Fraud')

ax.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)
ax.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)
ax.set_title('PCA', fontsize=14)

ax.grid(True)

ax.legend(handles=[blue_patch, red_patch])
```
- This plot shows us that classification models should perform well in distinguishing fraud cases from non-fraud cases.
:::


## Question2: Analysis Plan {style="font-size: 0.7em;"}
::: incremental

-  <b>Stacked Generalization Setup:</b> Utilize the mlxtend library to implement stacked generalization. Train base models as specified, and split their output into training and testing sets for the meta-classifier.

-  <b>Meta-classifier Training:</b> Combine predictions from base classifiers using the stacking method, and train a meta-classifier on these combined predictions to enhance prediction accuracy.

-  <b>Evaluation and Analysis:</b> Assess the performance of the stacked model, compare it to the base models, and analyze the performance gains, focusing on factors like model diversity, ensemble principles, and dataset specifics.

:::


## Plots

```{python}
penguins['species'] = penguins['species'].apply(lambda x: "Adelie" if x == "Adelie" else "Other")
sns.scatterplot(data=penguins, x='flipper_length_mm', y='body_mass_g', hue='species')
plt.show()
```

## Plot and text

::: columns
::: {.column width="50%"}
-   Some text

-   goes here
:::

::: {.column width="50%"}
```{python}
#| warning: false
#| fig.width: 5.5
fig, ax = plt.subplots(figsize=(5.5, 5.5 * 0.618))
sns.boxplot(data=penguins, x='bill_length_mm', y='species', hue='species', ax=ax)
plt.show()
```
:::
:::

# A new section...

## Tables

If you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,

```{python}
penguins.head().to_html()
```

## Images

![Image credit: Danielle Navarro, Percolate.](images/watercolour_sys02_img34_teacup-ocean.png){fig-align="center" width="500"}

## Math Expressions {.smaller}

You can write LaTeX math expressions inside a pair of dollar signs, e.g. \$\\alpha+\\beta\$ renders $\alpha + \beta$. You can use the display style with double dollar signs:

```         
$$\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$$
```

$$
\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i
$$

Limitations:

1.  The source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting `$$` must appear in the very beginning of a line, followed immediately by a non-space character, and the ending `$$` must be at the end of a line, led by a non-space character;

2.  There should not be spaces after the opening `$` or before the closing `$`.

# Wrap up

## Feeling adventurous?

-   You are welcomed to use the default styling of the slides. In fact, that's what I expect majority of you will do. You will differentiate yourself with the content of your presentation.

-   But some of you might want to play around with slide styling. Some solutions for this can be found at https://quarto.org/docs/presentations/revealjs.
