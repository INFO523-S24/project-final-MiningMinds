{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: load-pkgs\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "id": "load-pkgs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Setup \n"
      ],
      "id": "5e3efa1a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\".././data/creditcard_2023.csv\")\n",
        "\n",
        "# Selected features\n",
        "features = [\"V10\", \"V4\", \"V14\", \"V12\", \"V11\", \"V17\", \"V16\", \"V7\", \"V3\", \"V2\"]\n",
        "\n",
        "# Features data\n",
        "X = df[features]\n",
        "\n",
        "# Target variable\n",
        "y = df['Class']\n",
        "\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)"
      ],
      "id": "c2acbc2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost classifier\n"
      ],
      "id": "08ea87d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: XGBoost classifier\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "random_state = 42\n",
        "test_size = 0.2\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb = XGBClassifier(random_state=random_state, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Set up the hyperparameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "}\n",
        "\n",
        "# Perform Randomized Search\n",
        "random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=10, scoring='roc_auc', cv=3, verbose=1, random_state=random_state)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best estimator\n",
        "best_xgb = random_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "y_prob = best_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute metrics\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Print the results\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)"
      ],
      "id": "XGBoost-classifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  KNN classifier\n"
      ],
      "id": "2ac65315"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: KNN classifier\n",
        "\n",
        "# Creating the KNN model\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = knn.predict(X_train)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", acc)\n",
        "\n",
        "# Precision, Recall, and F1 Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# ROC-AUC\n",
        "y_probs = knn.predict_proba(X_train)[:, 1]  # Probability estimates for the positive class\n",
        "auc = roc_auc_score(y_test, y_probs)\n",
        "print(\"AUC-ROC:\", auc)\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='KNN (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Setup for learning curve data\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    knn,  # the model\n",
        "    X_train_scaled,  # feature matrix\n",
        "    y_train,  # response vector, make sure this matches the scaled features in size\n",
        "    cv=5,  # number of folds in cross-validation\n",
        "    n_jobs=-1,  # use all computer cores\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10)  # 10 evenly spaced relative intervals for training set sizes\n",
        ")\n",
        "\n",
        "# Calculate mean and standard deviation for training set scores\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "\n",
        "# Calculate mean and standard deviation for test set scores\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plotting the learning curve\n",
        "plt.figure()\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.xlabel(\"Training examples\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n"
      ],
      "id": "KNN-classifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest classifier\n"
      ],
      "id": "cc13d076"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Random Forest classifier\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = rf.predict(X_test)\n",
        "y_pred_prob = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculating performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"ROC-AUC: {roc_auc}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "id": "Random-Forest-classifier",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}