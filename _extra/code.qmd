

```{python}
#| label: load-pkgs
#| message: false

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from xgboost import XGBClassifier
```


## Dataset Setup
```{python}
#| label:  XGBoost classifier
# Load the dataset
df = pd.read_csv(".././data/creditcard_2023.csv")

print(df.columns)

# Select features
features = ["V10", "V4", "V14", "V12", "V11", "V17", "V16", "V7", "V3", "V2"]
X = df[features]
y = df['Class']

# Split the data into training and testing sets
random_state = 42
test_size = 0.2
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

# Initialize the XGBoost classifier
xgb = XGBClassifier(random_state=random_state, use_label_encoder=False, eval_metric='logloss')

# Set up the hyperparameter grid for RandomizedSearchCV
param_dist = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [3, 5, 7],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
}

# Perform Randomized Search
random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=10, scoring='roc_auc', cv=3, verbose=1, random_state=random_state)
random_search.fit(X_train, y_train)

# Best estimator
best_xgb = random_search.best_estimator_

# Make predictions
y_pred = best_xgb.predict(X_test)
y_prob = best_xgb.predict_proba(X_test)[:, 1]

# Compute metrics
conf_matrix = confusion_matrix(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
auc_roc = roc_auc_score(y_test, y_prob)

# Print the results
print("Confusion Matrix:\n", conf_matrix)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("AUC-ROC:", auc_roc)
```



## Plots
```{python}


```
